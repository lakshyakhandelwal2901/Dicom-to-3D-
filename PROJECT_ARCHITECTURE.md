# Project Architecture & Technical Overview

**Phase**: 1 Complete, Phase 2 Starting  
**Date**: Jan 2026  
**Status**: Production-Ready Foundation + AI Integration Planned

---

## ðŸ—ï¸ Overall Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER INTERFACE                          â”‚
â”‚  main.py (CLI) with flags: --organ, --input, --output, --model  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚                   â”‚                   â”‚
     â–¼                   â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Config Loaderâ”‚   â”‚DICOM Loader  â”‚   â”‚Model Selector      â”‚
â”‚(YAML parse) â”‚   â”‚(HU convert)  â”‚   â”‚(HU vs TotalSeg)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                 â”‚                    â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ Segmentation Engine          â”‚
          â”‚ (Config-Driven)              â”‚
          â”‚                              â”‚
          â”‚ â”œâ”€ HU-based path (Phase 1)   â”‚
          â”‚ â”œâ”€ TotalSegmentator (Phase2A)â”‚
          â”‚ â”œâ”€ MONAI (Phase 2B)          â”‚
          â”‚ â””â”€ nnU-Net (Phase 2C)        â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                 â”‚                 â”‚
       â–¼                 â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Thresholdingâ”‚   â”‚Morphological â”‚   â”‚Mesh Gen      â”‚
â”‚(HU-based)  â”‚   â”‚Ops           â”‚   â”‚(Marching Cubes)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”œâ”€ Dilation   â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”œâ”€ Erosion    â”‚          â”‚
                 â”œâ”€ Closing    â”‚          â–¼
                 â”œâ”€ Fill Holes â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â””â”€ Median     â”‚   â”‚Mesh Processingâ”‚
                               â”‚   â”‚â”œâ”€ Laplacian   â”‚
                               â”‚   â”‚â””â”€ Decimate    â”‚
                               â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚           â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                           â”‚           â”‚
                                           â–¼           â–¼
                                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                       â”‚STL File â”‚ â”‚PLY File  â”‚
                                       â”‚(Binary) â”‚ â”‚(Colored) â”‚
                                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“ Phase 1 - Current Production Structure

### Directory Layout

```
medical_imaging_platform/
â”‚
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ dicom_loader.py          âœ… COMPLETE - Load DICOM â†’ 3D volume
â”‚   â”‚   â”œâ”€â”€ load_dicom_series()
â”‚   â”‚   â”œâ”€â”€ normalize_to_hu()
â”‚   â”‚   â””â”€â”€ resample_volume()
â”‚   â”‚
â”‚   â”œâ”€â”€ segmentation_engine.py   âœ… COMPLETE - Generic config-driven engine
â”‚   â”‚   â”œâ”€â”€ __init__(config)
â”‚   â”‚   â”œâ”€â”€ process()            Main entry point
â”‚   â”‚   â””â”€â”€ segment_tissue()
â”‚   â”‚
â”‚   â””â”€â”€ [NEW - Phase 2] model_loader.py
â”‚       â”œâ”€â”€ load_model()
â”‚       â”œâ”€â”€ segment_with_totalseg()
â”‚       â””â”€â”€ segment_with_monai()
â”‚
â”œâ”€â”€ profiles/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config_loader.py         âœ… COMPLETE - Parse YAML configs
â”‚   â”‚   â”œâ”€â”€ load(organ_name)
â”‚   â”‚   â”œâ”€â”€ list_available()
â”‚   â”‚   â””â”€â”€ validate_config()
â”‚   â”‚
â”‚   â”œâ”€â”€ brain.yaml               âœ… (HU: shell 120-3000, brain 0-150)
â”‚   â”œâ”€â”€ liver.yaml               âœ… (HU: tissue 40-100, vessels 100-200)
â”‚   â”œâ”€â”€ lungs.yaml               âœ… (HU: tissue -500 to -100, airways -1000 to -600)
â”‚   â”œâ”€â”€ heart.yaml               âœ… (HU: myocardium 40-120, chambers 100-200)
â”‚   â”œâ”€â”€ kidneys.yaml             âœ… (HU: cortex 40-80, medulla 30-50)
â”‚   â”œâ”€â”€ bones.yaml               âœ… (HU: cortical 300-1500, trabecular 100-400)
â”‚   â”œâ”€â”€ pancreas.yaml            âœ… (HU: tissue 35-90, ducts -10 to 30)
â”‚   â”‚
â”‚   â””â”€â”€ [NEW - Phase 2] 
â”‚       â”œâ”€â”€ brain_totalseg.yaml  (model_type: totalSegmentator)
â”‚       â””â”€â”€ pancreas_nnunet.yaml (model_type: nnunet with fine-tuning)
â”‚
â”œâ”€â”€ main.py                      âœ… COMPLETE - CLI entry point
â”‚   â”œâ”€â”€ --organ ORGAN_NAME
â”‚   â”œâ”€â”€ --input DICOM_FOLDER
â”‚   â”œâ”€â”€ --output OUTPUT_FOLDER
â”‚   â”œâ”€â”€ --list-profiles
â”‚   â””â”€â”€ [NEW] --model hu_based|totalSegmentator|monai|nnunet
â”‚
â”œâ”€â”€ requirements.txt             âœ… COMPLETE
â”‚   â””â”€â”€ [NEW] + totalsegmentator, torch, nnunet
â”‚
â””â”€â”€ output/                      (Generated outputs)
    â””â”€â”€ brain_segmentation/
        â”œâ”€â”€ brain_shell.stl
        â”œâ”€â”€ brain_shell_colored.ply
        â”œâ”€â”€ brain_brain.stl
        â””â”€â”€ brain_brain_colored.ply
```

---

## ðŸ§® Phase 2A - TotalSegmentator Integration

### Implementation Plan

**File**: `core/model_loader.py` (NEW)

```python
from totalsegmentator.python_api import totalsegmentator
from trimesh import Trimesh

class PreTrainedModelLoader:
    def __init__(self, model_type="totalSegmentator"):
        self.model_type = model_type
        
    def segment(self, volume, config):
        """
        Args:
            volume: 3D numpy array (HU values)
            config: Organ config dict from YAML
        
        Returns:
            segmentations: dict of {tissue_name: binary_mask}
        """
        if self.model_type == "totalSegmentator":
            return self._segment_totalSegmentator(volume, config)
        elif self.model_type == "monai":
            return self._segment_monai(volume, config)
        # ... etc
    
    def _segment_totalSegmentator(self, volume, config):
        # Call TotalSegmentator API
        # Return dict of tissue masks
        pass
```

**Config Example** (`profiles/brain.yaml`):
```yaml
organ: Brain
model_type: totalSegmentator      # â† NEW FIELD

tissues:
  - name: brain
    description: Brain tissue
    color: [139, 69, 19]
    # No HU range needed (model handles it)
    
  - name: shell
    description: Skull
    color: [211, 211, 211]
```

**Integration in segmentation_engine.py**:
```python
def __init__(self, config):
    self.config = config
    self.model_type = config.get("model_type", "hu_based")
    
    if self.model_type == "hu_based":
        self.segmentation_fn = self._segment_hu_based
    elif self.model_type == "totalSegmentator":
        self.model_loader = PreTrainedModelLoader("totalSegmentator")
        self.segmentation_fn = self.model_loader.segment
```

---

## ðŸ“Š Phase 2B - Data Collection & Organization

### Data Directory Structure

```
data/datasets/
â”œâ”€â”€ medical_segmentation_decathlon/
â”‚   â”œâ”€â”€ Task01_Brain/
â”‚   â”‚   â”œâ”€â”€ imagesTr/
â”‚   â”‚   â”‚   â”œâ”€â”€ br_000.nii.gz
â”‚   â”‚   â”‚   â””â”€â”€ ... (484 training scans)
â”‚   â”‚   â”œâ”€â”€ labelsTr/
â”‚   â”‚   â”‚   â”œâ”€â”€ br_000.nii.gz
â”‚   â”‚   â”‚   â””â”€â”€ ... (484 masks)
â”‚   â”‚   â””â”€â”€ imagesTs/ (100 test scans)
â”‚   â”‚
â”‚   â”œâ”€â”€ Task03_Liver/
â”‚   â”œâ”€â”€ Task05_Pancreas/
â”‚   â”œâ”€â”€ Task07_Lungs/
â”‚   â””â”€â”€ Task10_Kidney/
â”‚
â”œâ”€â”€ lits_liver/
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ volume-*.nii
â”‚   â”‚   â””â”€â”€ segmentation-*.nii
â”‚   â””â”€â”€ testing/
â”‚
â”œâ”€â”€ kits_kidney/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ case_00000/
â”‚   â”‚   â”‚   â”œâ”€â”€ imaging.nii.gz
â”‚   â”‚   â”‚   â””â”€â”€ segmentation.nii.gz
â”‚   â”‚   â””â”€â”€ ... (300 cases)
â”‚
â”œâ”€â”€ chaos_multimodal/
â”œâ”€â”€ synapse_validation/
â”‚
â”œâ”€â”€ custom_institutional/
â”‚   â”œâ”€â”€ unlabeled/
â”‚   â”‚   â””â”€â”€ scan_*/  (DICOM folders)
â”‚   â””â”€â”€ annotated/
â”‚       â””â”€â”€ scan_*/  (With manual annotations)
â”‚
â””â”€â”€ dataset_inventory.csv
    (Track all sources, sizes, quality metrics)
```

---

## ðŸ§  Phase 2C - Fine-Tuning Architecture

### nnU-Net Integration Path

```python
# core/nnunet_wrapper.py

from nnunetv2.paths import nnUNet_raw, nnUNet_preprocessed

class nnUNetFinetuner:
    def __init__(self, config):
        self.config = config
        self.dataset_id = "Dataset100_YourOrgan"
    
    def prepare_dataset(self, train_images, train_labels):
        """Convert medical images to nnU-Net format"""
        # Copy to nnUNet_raw/dataset_id/imagesTs/, labelsTs/
        # Create dataset.json with metadata
        pass
    
    def finetune(self, gpu_id=0):
        """Train on custom data"""
        # nnunetv2_train Dataset100 3d_fullres 0 --npz
        pass
    
    def predict(self, test_image):
        """Use fine-tuned model"""
        # nnunetv2_predict -i input -o output -d Dataset100
        pass
```

### Training Configuration

```yaml
# profiles/pancreas_finetuned.yaml
organ: Pancreas
model_type: nnunet
model_checkpoint: nnUNet_v2_dataset100

training:
  dataset_id: "Dataset100_Pancreas"
  base_model: "nnUNet_v2"  # Start from this
  epochs: 100
  batch_size: 4
  learning_rate: 0.001
  
tissues:
  - name: pancreatic_tissue
    description: Pancreatic parenchyma
    color: [255, 165, 0]
  - name: pancreatic_ducts
    description: Pancreatic ducts
    color: [255, 215, 0]
```

---

## ðŸ”„ Data Flow Comparison (Phase 1 vs 2 vs 3)

### Phase 1 - Current (HU-Based)

```
DICOM Files
    â†“
dicom_loader.py (convert to HU)
    â†“
segmentation_engine.py
    â”‚
    â”œâ”€ Body mask (HU > -800)
    â”œâ”€ Thresholding by HU range (config driven)
    â”œâ”€ Morphological ops (closing, dilation, etc.)
    â”œâ”€ Marching cubes
    â”œâ”€ Laplacian smoothing
    â””â”€ STL/PLY export
```

**Pros**: Fast (1 min/scan), interpretable, no training needed  
**Cons**: Limited accuracy (88%), organ-specific tuning needed

### Phase 2A - TotalSegmentator (AI, No Training)

```
DICOM Files
    â†“
Convert to NIfTI
    â†“
TotalSegmentator API
    â”œâ”€ Pre-trained 3D U-Net (20K scan training)
    â”œâ”€ Predicts 117 organs simultaneously
    â””â”€ Returns segmentation mask
    â†“
segmentation_engine.py
    â”œâ”€ Extract specific tissues from mask
    â”œâ”€ Post-processing (morphology, smoothing)
    â””â”€ STL/PLY export
```

**Pros**: Much better accuracy (91-92%), works for all organs, no data collection  
**Cons**: Fixed tissues, can't customize

### Phase 2C - Fine-Tuned nnU-Net (AI + Custom Training)

```
Training Phase:
  Your 500-1000 labeled scans
    â†“
  nnU-Net auto-configures architecture
    â†“
  Train on GPU (24-72 hours)
    â†“
  Fine-tuned checkpoint saved

Inference Phase:
  DICOM Files
    â†“
  Fine-tuned nnU-Net
    â”œâ”€ Transfer learning on your data
    â”œâ”€ Better accuracy for YOUR domain
    â””â”€ Predicts custom tissue classes
    â†“
  segmentation_engine.py
    â”œâ”€ Post-processing
    â””â”€ STL/PLY export
```

**Pros**: Best accuracy (95%+), customized to your domain, YOUR intellectual property  
**Cons**: Requires 500+ labeled scans, GPU compute ($2-5K), 8-12 week timeline

---

## ðŸŽ¯ Tech Stack

### Current (Phase 1)

```
Core Dependencies:
â”œâ”€ PyDICOM (read DICOM files)
â”œâ”€ NumPy (array operations)
â”œâ”€ SciPy (ndimage morphology)
â”œâ”€ scikit-image (marching cubes)
â”œâ”€ Trimesh (mesh generation)
â”œâ”€ PyYAML (config parsing)
â””â”€ Python 3.8+

Development:
â”œâ”€ Git (version control)
â”œâ”€ Docker (optional containerization)
â””â”€ Jupyter (analysis notebooks)

File Formats:
â”œâ”€ DICOM (.dcm)
â”œâ”€ NIfTI (.nii.gz)
â”œâ”€ STL (.stl binary/ASCII)
â””â”€ PLY (.ply with vertex colors)
```

### New for Phase 2

```
Phase 2A:
â”œâ”€ TotalSegmentator (pip install totalsegmentator)
â”œâ”€ PyTorch (dependency of TotalSegmentator)
â””â”€ ONNX Runtime (inference optimization)

Phase 2B/2C:
â”œâ”€ MONAI (medical imaging toolkit)
â”œâ”€ nnU-Net v2 (pip install nnunetv2)
â”œâ”€ Torch Lightning (training framework)
â”œâ”€ Hydra (config management)
â””â”€ Optuna (hyperparameter tuning)

Data Handling:
â”œâ”€ SimpleITK (DICOM/NIfTI I/O)
â”œâ”€ nibabel (NIfTI I/O)
â”œâ”€ h5py (HDF5 storage)
â””â”€ Git LFS (large file storage)

Validation:
â”œâ”€ Monai Metrics (Dice, Hausdorff)
â”œâ”€ scikit-learn (classification metrics)
â””â”€ Matplotlib (visualization)
```

---

## ðŸ” Version Control Strategy

```
Workspace Structure:
â”œâ”€â”€ src/
â”‚   â””â”€â”€ medical_imaging_platform/
â”‚       â”œâ”€â”€ core/
â”‚       â”œâ”€â”€ profiles/
â”‚       â””â”€â”€ main.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ sample_brain_ct/          (Small sample, in repo)
â”‚   â”œâ”€â”€ datasets/                 (Large, in Git LFS)
â”‚   â”‚   â”œâ”€â”€ .gitattributes        (*.nii.gz filter=lfs)
â”‚   â”‚   â””â”€â”€ [DICOM files]
â”‚   â””â”€â”€ output/
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ pretrained/               (Downloaded, not in repo)
â”‚   â”‚   â””â”€â”€ totalsegmentator_*
â”‚   â””â”€â”€ finetuned/                (In Git LFS after training)
â”‚       â””â”€â”€ dataset100_nnunet_*
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ HYBRID_APPROACH.md        (This doc)
â”‚   â”œâ”€â”€ DATASETS.md
â”‚   â”œâ”€â”€ MODELS.md
â”‚   â””â”€â”€ PROJECT_ARCHITECTURE.md   (This file)
â”‚
â”œâ”€â”€ notebooks/                    (Analysis & experimentation)
â”‚   â”œâ”€â”€ phase2a_test_totalseg.ipynb
â”‚   â”œâ”€â”€ phase2b_dataset_analysis.ipynb
â”‚   â””â”€â”€ phase2c_finetuning.ipynb
â”‚
â””â”€â”€ .gitignore
    /models/pretrained/          (Too large, auto-download)
    /data/datasets/raw/          (Or use Git LFS)
    __pycache__/
    *.egg-info/
```

---

## ðŸš€ Deployment Roadmap

### Timeline

```
Week 1-2   [Phase 2A] Deploy TotalSegmentator
â”œâ”€ Install totalsegmentator
â”œâ”€ Create model_loader.py wrapper
â”œâ”€ Test on sample_brain_ct
â”œâ”€ Benchmark accuracy & speed
â””â”€ Update main.py with --model flag
   Status: âœ… Ready to implement

Week 2-8   [Phase 2B] Collect & Organize Data
â”œâ”€ Download Medical Decathlon
â”œâ”€ Download LiTS, KITS, CHAOS, Synapse
â”œâ”€ Collect custom institutional scans
â”œâ”€ Annotate 100-200 custom scans
â””â”€ Create combined training dataset
   Status: âœ… Ready to implement

Week 8-12  [Phase 2C] Fine-Tune Custom Model
â”œâ”€ Install nnunetv2
â”œâ”€ Prepare dataset in nnU-Net format
â”œâ”€ Configure training parameters
â”œâ”€ Train on GPU (50-100 hours)
â”œâ”€ Validate on test set
â””â”€ Deploy fine-tuned model
   Status: âœ… Ready to implement

Week 12+   [Phase 3] Slicer Integration (Optional)
â””â”€ Reverse-engineer Segment Editor effects
```

---

## ðŸ“ˆ Success Metrics (Phase 1-3)

| Phase | Accuracy | Speed | Cost | Effort |
|-------|----------|-------|------|--------|
| **Phase 1 (Current)** | 88-92% | 1 min | $0 | Done |
| **Phase 2A** | 91-93% | 3 min | $0 | 2 weeks |
| **Phase 2B** | 91-93% | 3 min | $0-5K | 6 weeks |
| **Phase 2C** | 95%+ | 5 min | $2-5K | 4 weeks |
| **Phase 3** | 96%+ | 5 min | $1-2K | 8 weeks |

---

## ðŸŽ“ Key Design Decisions

1. **Config-Driven Over Hardcoding**
   - Each organ is a YAML file
   - No code changes needed to add organs
   - Easy to version and track changes

2. **Modular Segmentation Engine**
   - Same engine processes any organ
   - Pluggable backends (HU, TotalSeg, MONAI, nnU-Net)
   - Easy to swap algorithms

3. **Hybrid Approach Over Pure AI**
   - Phase 1 (HU) provides immediate value
   - Phase 2A (TotalSeg) improves accuracy
   - Phase 2C (fine-tuning) optimizes for your domain

4. **Open-Source Dependencies**
   - No proprietary licenses
   - Community-maintained
   - Can audit code

5. **Medical Imaging Standards**
   - DICOM input (medical standard)
   - NIfTI for datasets (research standard)
   - STL/PLY for 3D printing (industry standard)

---

## â“ FAQ

**Q: Do I need to implement Phase 2A before 2C?**  
A: No. Phase 2A is independent. But Phase 2A â†’ 2B â†’ 2C is recommended (quick wins first).

**Q: Can I skip Phase 2B?**  
A: No. Phase 2C (nnU-Net) requires labeled training data.

**Q: Should I use TotalSegmentator results as ground truth?**  
A: Only if >90% accurate on your scans. Otherwise collect expert annotations.

**Q: How much GPU memory do I need for fine-tuning?**  
A: Minimum 8 GB. Recommended 16+ GB. RTX 3080/A100 optimal.

**Q: Can I use pre-trained models on MRI?**  
A: Not TotalSegmentator (CT-only). Some MONAI models support MRI.

---

## ðŸ”— Related Documentation

- [HYBRID_APPROACH.md](HYBRID_APPROACH.md) - Strategy & timeline
- [MODELS.md](MODELS.md) - Model comparison
- [DATASETS.md](DATASETS.md) - Data collection guide
- [DATA_COLLECTION_WORKFLOW.md](DATA_COLLECTION_WORKFLOW.md) - Annotation process

---

**Last Updated**: Jan 22, 2026  
**Next Review**: After Phase 2A completion
